{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pdfplumber\n",
    "import pdfminer\n",
    "import pdf2image\n",
    "#fit is the lbi name fo thepyMUPDF suite\n",
    "import fitz\n",
    "\n",
    "import layoutparser as lp\n",
    "from easyocr import Reader\n",
    "\n",
    "import cv2 as cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "easyocr.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erode the images first\n",
    "def img_blob_it(img,k=50):\n",
    "    kernel = np.ones((k,k),np.uint8)\n",
    "    eroded = cv2.erode(img, kernel, iterations = 1)\n",
    "\n",
    "    return eroded\n",
    "\n",
    "def img_dif(file_1, file_2, blob = False,k=50):\n",
    "    img_1 = cv2.imread(file_1)\n",
    "    img_2 = cv2.imread(file_2)\n",
    "    if blob:\n",
    "       img_1 =  img_blob_it(img_1,k)\n",
    "       img_2 =  img_blob_it(img_2,k)\n",
    "\n",
    "    diff = img_1.copy()\n",
    "    diff = cv2.absdiff(img_1, img_2, diff)\n",
    "\n",
    "    plt.figure(figsize = (20,15))\n",
    "    plt.imshow(diff)\n",
    "    plt.show()\n",
    "    if blob:\n",
    "        img_1 = cv2.imread(file_1)\n",
    "        img_2 = cv2.imread(file_2)\n",
    "        \n",
    "    return img_1, img_2, diff\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab local files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding hte pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./crime_lab_roof/crime_plans_page_\"\n",
    "p = '0'\n",
    "img_path = root_path+p+\".jpeg\"\n",
    "img_1 = cv2.imread(img_path)\n",
    "img_1 = cv2.cvtColor(img_1, cv2.COLOR_BGR2GRAY)\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(img_1, cmap='gray')\n",
    "plt.title(\"first img\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "p = '1'\n",
    "img_path = root_path+p+\".jpeg\"\n",
    "img_2 = cv2.imread(img_path)\n",
    "img_2 = cv2.cvtColor(img_2, cv2.COLOR_BGR2GRAY)\n",
    "print(img_2.shape)\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.title(\"second img\")\n",
    "plt.imshow(img_2, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sum = img_1.astype(np.float) + img_2.astype(np.float)\n",
    "sum_scaled = np.divide(sum, 255)\n",
    "\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(sum_scaled, cmap='gray')\n",
    "plt.title(\"Imgs Sum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So using the numpy and opencv image fucntions scale/ module again the 256 satuatation for a image pxiel,\n",
    "## instead I need to treat all as a array until showi time, divide every by 255 before showing. This should help get th intensity relative to frequency of values being added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using numpy/ oepncv Summing operations\n",
    "\n",
    "img_path = \"./crime_lab_roof/crime_plans_page_\"+str(0)+\".jpeg\"\n",
    "orig = cv2.imread(img_path)\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(orig)\n",
    "plt.show()\n",
    "\n",
    "for i in range(8):\n",
    "    img_path = \"./crime_lab_roof/crime_plans_page_\"+str(i+1)+\".jpeg\"\n",
    "    img_2 = cv2.imread(img_path)\n",
    "    \n",
    "\n",
    "    orig = cv2.add(orig, img_2)\n",
    "    #orig = orig + img_2\n",
    "\n",
    "    plt.figure(figsize = (20,15))\n",
    "    plt.imshow(orig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_img_set(root_path,pg_cnt = 8, method = \"np\"):\n",
    "    img_path = root_path+str(0)+\".jpeg\"\n",
    "    orig = cv2.imread(img_path)\n",
    "    plt.figure(figsize = (20,15))\n",
    "    plt.imshow(orig)\n",
    "    plt.show()\n",
    "    \n",
    "    for i in range(pg_cnt):\n",
    "        img_path = root_path+str(i+1)+\".jpeg\"\n",
    "        img_2 = cv2.imread(img_path)\n",
    "        \n",
    "\n",
    "        if method == \"np\":\n",
    "            #np method is based on modolo 256\n",
    "            orig = orig + img_2\n",
    "        else:\n",
    "            #cv method \"satruates\" at 255 value for a pixel\n",
    "            orig = cv2.add(orig, img_2)\n",
    "        \n",
    "        plt.figure(figsize = (20,15))\n",
    "        plt.imshow(orig)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./crime_lab_roof/crime_plans_page_\"\n",
    "m = \"np\"\n",
    "\n",
    "sum_img_set(root_path,pg_cnt = 8, method = m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./crime_lab_roof/crime_plans_page_\"\n",
    "m = \"cv\"\n",
    "\n",
    "sum_img_set(root_path,pg_cnt = 8, method = m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./crime_lab_roof/kirby_pages/kirby_plans_img_\"\n",
    "m = \"np\"\n",
    "\n",
    "sum_img_set(root_path,pg_cnt = 10, method = m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using numpy/ oepncv Summing operations\n",
    "#blob the images before adding\n",
    "\n",
    "root_path = \"./crime_lab_roof/crime_plans_page_\"\n",
    "root_path = \"./crime_lab_roof/kirby_pages/kirby_plans_img_\"\n",
    "\n",
    "img_path = root_path+str(0)+\".jpeg\"\n",
    "orig = cv2.imread(img_path)\n",
    "\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(orig)\n",
    "plt.show()\n",
    "\n",
    "orig = img_blob_it(orig, k =10)\n",
    "for i in range(8):\n",
    "    img_path = root_path+str(i+1)+\".jpeg\"\n",
    "    img_2 = cv2.imread(img_path)\n",
    "    img_2 = img_blob_it(img_2, k =10)\n",
    "    \n",
    "\n",
    "    #orig = cv2.add(orig, img_2)\n",
    "    orig = orig + img_2\n",
    "\n",
    "    plt.figure(figsize = (20,15))\n",
    "    plt.imshow(orig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy SCaling the sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treat the images as number arrays and then scale them to see the relative intestity of pixels\n",
    "\n",
    "\n",
    "root_path = \"./crime_lab_roof/crime_plans_page_\"\n",
    "#root_path = \"./crime_lab_roof/kirby_pages/kirby_plans_img_\"\n",
    "\n",
    "img_path = root_path+str(0)+\".jpeg\"\n",
    "orig = cv2.imread(img_path)\n",
    "\n",
    "sum = cv2.imread(img_path)\n",
    "sum = cv2.cvtColor(sum, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#plt.figure(figsize = (20,15))\n",
    "#plt.imshow(orig)\n",
    "#plt.show()\n",
    "for i in range(8):\n",
    "    img_path = root_path+str(i+1)+\".jpeg\"\n",
    "    img_2 = cv2.imread(img_path)\n",
    "    orig = cv2.add(orig, img_2)\n",
    "   \n",
    "    plt.figure(figsize = (20,15))\n",
    "    plt.title(\"Imgs Sum Img CVOPS\")\n",
    "    plt.imshow(orig)\n",
    "    plt.show()\n",
    "    #orig = orig + img_2\n",
    "    \n",
    "    \n",
    "    img_2 = cv2.cvtColor(img_2, cv2.COLOR_BGR2GRAY)\n",
    "    sum = sum.astype(np.float) + img_2.astype(np.float)\n",
    "    sum_scaled = np.divide(sum, 255)\n",
    "\n",
    "    plt.figure(figsize = (20,15))\n",
    "    plt.imshow(sum_scaled, cmap='gray')\n",
    "    plt.title(\"Imgs NP ScaleSum\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#I want to remove \"noise\" anything less than a certain treshold\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(sum_scaled, cmap='gray')\n",
    "plt.title(\"Imgs Sum\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(sum_scaled[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.threshold(dilated, 3, 255, cv2.THRESH_BINARY)\n",
    "#cleaned = cv2.threshold(sum_scaled,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "img = sum_scaled.astype(np.uint8)\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#cleaned = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "_, cleaned = cv2.threshold(sum_scaled,8,255,cv2.THRESH_TRUNC)\n",
    "\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(cleaned, cmap='gray')\n",
    "plt.title(\"Cleaned Imgs Sum\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.uint8([255])\n",
    "y = np.uint8([255])\n",
    "print( cv2.add(x,y) )\n",
    "print( x+y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erode_np_sums = img_blob_it(orig, k= 5)\n",
    "\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(erode_np_sums)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(erode_np_sums, cv2.COLOR_BGR2GRAY)\n",
    "#increasing the size of differences so we can capture them all\n",
    "for i in range(0, 3):\n",
    "    dilated = cv2.dilate(gray.copy(), None, iterations= i+ 1)\n",
    "(T, thresh) = cv2.threshold(dilated, 3, 255, cv2.THRESH_BINARY)\n",
    " \n",
    "# now we need to find contours in the binarised image\n",
    "cnts = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "i = 0\n",
    "areas  = []\n",
    "boxes = []\n",
    "for c in cnts:\n",
    "    # fit a bounding box to the contour\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    bbox = [x, y, w, h]\n",
    "    #need to capture the rectangle and calcuates that area not the area of the contour\n",
    "    a = cv2.contourArea(c)\n",
    "    areas.append(a)\n",
    "    boxes.append(bbox)\n",
    "    cv2.rectangle(erode_np_sums, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    i+=1\n",
    "\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(erode_np_sums)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = (7500, 5250)\n",
    "f = (2/3)\n",
    "newsize = tuple(f*l for l in ns)\n",
    "newsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "\n",
    "doc1 = \"/Users/melanieyennam/Documents/Ventures/CD_nav_protyping/raw_docs/Plans/Baptist Kirby PLANS.pdf\"\n",
    "root_path = \"./crime_lab_roof/kirby_pages/\"\n",
    "output_names = \"/kirby_plans_img_\"\n",
    "\n",
    "\n",
    "for i, page in enumerate(pdf2image.convert_from_path(doc1)):\n",
    "    ns = (7500, 5250)\n",
    "    f = (2/3)\n",
    "    newsize = tuple(f*l for l in ns)\n",
    "\n",
    "    p = page.resize(newsize)\n",
    "    img_gray = ImageOps.grayscale(p)\n",
    "    \n",
    "    img_path = root_path + output_names + str(i) + \".jpeg\"\n",
    "    img_gray.save(img_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "img_path = \"./crime_lab_roof/kirby_pages/\"+output_names+str(p)+\".jpeg\"\n",
    "orig = cv2.imread(img_path)\n",
    "print(orig.shape)\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(orig)\n",
    "plt.show()\n",
    "orig = img_blob_it(orig)\n",
    "\n",
    "for i in range(8):\n",
    "    img_path = \"./crime_lab_roof/kirby_pages/\"+output_names+str(p)+\".jpeg\"\n",
    "    img_2 = cv2.imread(img_path)\n",
    "    img_2 = img_blob_it(img_2)\n",
    "    #print(img_2.shape)\n",
    "\n",
    "    orig = cv2.add(orig, img_2)\n",
    "    #orig = orig + img_2\n",
    "\n",
    "    plt.figure(figsize = (20,15))\n",
    "    plt.imshow(orig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum Via cv bitwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pic(img):\n",
    "    plt.figure(figsize = (20,15))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load two images\n",
    "p = '0'\n",
    "img_path = \"./crime_lab_roof/crime_plans_page_\"+p+\".jpeg\"\n",
    "img_1 = cv2.imread(img_path)\n",
    "p = '1'\n",
    "img_path = \"./crime_lab_roof/crime_plans_page_\"+p+\".jpeg\"\n",
    "img_2 = cv2.imread(img_path)\n",
    "\n",
    "# I want to put logo on top-left corner, So I create a ROI - dont need this in my context\n",
    "rows,cols,channels = img_2.shape\n",
    "roi = img_1[0:rows, 0:cols]\n",
    "# Now create a mask of logo and create its inverse mask also\n",
    "img2gray = cv2.cvtColor(img_2,cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "# Now black-out the area of logo in ROI\n",
    "img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "plot_pic(img1_bg)\n",
    "# Take only region of logo from logo image.\n",
    "img2_fg = cv2.bitwise_and(img_2,img_2,mask = mask)\n",
    "plot_pic(img2_fg)\n",
    "# Put logo in ROI and modify the main image\n",
    "dst = cv2.add(img1_bg,img2_fg)\n",
    "img_1[0:rows, 0:cols ] = dst\n",
    "\n",
    "plot_pic(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Image Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erode the images first\n",
    "def img_blob_it(img,k=50):\n",
    "    kernel = np.ones((k,k),np.uint8)\n",
    "    eroded = cv2.erode(img, kernel, iterations = 1)\n",
    "\n",
    "    return eroded\n",
    "\n",
    "def img_dif(file_1, file_2, blob = False,k =50):\n",
    "    img_1 = cv2.imread(file_1)\n",
    "    img_2 = cv2.imread(file_2)\n",
    "    if blob:\n",
    "       img_1 =  img_blob_it(img_1,k)\n",
    "       img_2 =  img_blob_it(img_2,k)\n",
    "\n",
    "    diff = img_1.copy()\n",
    "    diff = cv2.absdiff(img_1, img_2, diff)\n",
    "\n",
    "    plt.figure(figsize = (20,15))\n",
    "    plt.imshow(diff)\n",
    "    plt.show()\n",
    "    if blob:\n",
    "        img_1 = cv2.imread(file_1)\n",
    "        img_2 = cv2.imread(file_2)\n",
    "        \n",
    "    return img_1, img_2, diff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./crime_lab_roof/crime_plans_page_\"\n",
    "root_path = \"./crime_lab_roof/kirby_pages/kirby_plans_img_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '4'\n",
    "img_path_1 = root_path+p+\".jpeg\"\n",
    "\n",
    "p = '5'\n",
    "img_path_2 = root_path+p+\".jpeg\"\n",
    "\n",
    "_, _, diff = img_dif(img_path_1, img_path_2, blob = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '4'\n",
    "img_path_1 = root_path+p+\".jpeg\"\n",
    "\n",
    "p = '5'\n",
    "img_path_2 = root_path+p+\".jpeg\"\n",
    "\n",
    "img_1, img_2, diff = img_dif(img_path_1, img_path_2, blob = True, k =15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where is the ther the biggest difference from the original image and where the image with the overlay removed? box that\n",
    "#capture the boarder are that has the least amount of pixels currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the difference into grascale\n",
    "gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "#increasing the size of differences so we can capture them all\n",
    "for i in range(0, 3):\n",
    "    dilated = cv2.dilate(gray.copy(), None, iterations= i+1)\n",
    "\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(dilated)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "\n",
    "(T, thresh) = cv2.threshold(dilated, 3, 255, cv2.THRESH_BINARY)\n",
    " \n",
    "# now we need to find contours in the binarised image\n",
    "cnts = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "i = 0\n",
    "areas  = []\n",
    "boxes = []\n",
    "for c in cnts:\n",
    "    # fit a bounding box to the contour\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    bbox = [x, y, w, h]\n",
    "    #need to capture the rectangle and calcuates that area not the area of the contour\n",
    "    a = cv2.contourArea(c)\n",
    "    areas.append(a)\n",
    "    boxes.append(bbox)\n",
    "    cv2.rectangle(diff, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(diff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rects = list(zip(cnts,areas,boxes))\n",
    "type(rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.groupRectangles(boxes, groupThreshold=1, eps = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_rects = pd.DataFrame(list(zip(cnts,areas,boxes)), columns = ['cnt_coord', 'areas', 'bbox_tlwh'])\n",
    "cnt_rects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_rects.sort_values('areas', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_rects.sort_values('areas', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = img_1.copy()\n",
    "x,y,w,h = 352, 181, 1684, 1169\n",
    "\n",
    "cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), -1)\n",
    "\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(orig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = img_2.copy()\n",
    "x,y,w,h = 352, 181, 1684, 1169\n",
    "\n",
    "cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), -1)\n",
    "\n",
    "plt.figure(figsize = (20,15))\n",
    "plt.imshow(orig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pdf_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a870548d95cd715955361f01c3cd534b1da74cc1fc12eb5b88316e41230a3cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
